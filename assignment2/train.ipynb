{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import prepare_functions\n",
    "import train_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved count vectorizer\n",
    "with open('bow_transformer.pickle', 'rb') as f:\n",
    "    bow_transformer = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 2)\n",
      "(836, 2)\n",
      "(836, 2)\n"
     ]
    }
   ],
   "source": [
    "# loading the datasets\n",
    "train_data = prepare_functions.load_data(\"data/train.csv\", separator=',')\n",
    "validation_data = prepare_functions.load_data(\"data/validation.csv\", separator=',')\n",
    "test_data = prepare_functions.load_data(\"data/test.csv\", separator=',')\n",
    "\n",
    "print(train_data.shape)\n",
    "print(validation_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 8731)\n",
      "(836, 8731)\n",
      "(836, 8731)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing the datasets, converting into sparse matrices\n",
    "train_matrix, train_labels = prepare_functions.preprocess(train_data, bow_transformer)\n",
    "validation_matrix, validation_labels = prepare_functions.preprocess(validation_data, bow_transformer)\n",
    "test_matrix, test_labels = prepare_functions.preprocess(test_data, bow_transformer)\n",
    "\n",
    "print(train_matrix.shape)\n",
    "print(validation_matrix.shape)\n",
    "print(test_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules for the three classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using mlflow to track and register the models\n",
    "import mlflow\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "def eval_metrics(model, modelname):\n",
    "    test_predictions = model.predict(test_matrix)\n",
    "\n",
    "    train_score = model.score(train_matrix, train_labels)\n",
    "    validation_score = model.score(validation_matrix, validation_labels)\n",
    "    test_score = model.score(test_matrix, test_labels)\n",
    "    \n",
    "    test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    test_precision = precision_score(test_labels, test_predictions)\n",
    "    test_recall = recall_score(test_labels, test_predictions)\n",
    "\n",
    "    print(modelname)\n",
    "    print(\"Test accuracy:\", test_accuracy)\n",
    "    print(\"Test precision: \", test_precision)\n",
    "    print(\"Test recall: \", test_recall)\n",
    "\n",
    "    return [\n",
    "        train_score,\n",
    "        validation_score,\n",
    "        test_score,\n",
    "        test_accuracy,\n",
    "        test_precision,\n",
    "        test_recall\n",
    "    ]\n",
    "\n",
    "def mlflow_run(modelclass, modelname):\n",
    "    with mlflow.start_run():\n",
    "        model = modelclass()\n",
    "        train_functions.train_model(model, train_matrix, train_labels)\n",
    "        [\n",
    "            train_score,\n",
    "            validation_score,\n",
    "            test_score,\n",
    "            test_accuracy,\n",
    "            test_precision,\n",
    "            test_recall\n",
    "        ] = eval_metrics(model, modelname)\n",
    "        \n",
    "        # logging metrics\n",
    "        mlflow.log_metric(\"train_score\", train_score)\n",
    "        mlflow.log_metric(\"validation_score\", validation_score)\n",
    "        mlflow.log_metric(\"test_score\", test_score)\n",
    "        mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "        mlflow.log_metric(\"test_precision\", test_precision)\n",
    "        mlflow.log_metric(\"test_recall\", test_recall)\n",
    "\n",
    "        # the following will store the model in mlruns\n",
    "        mlflow.sklearn.log_model(model, \"model\", registered_model_name=modelname)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes\n",
      "Test accuracy: 0.9366028708133971\n",
      "Test precision:  1.0\n",
      "Test recall:  0.5350877192982456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codetalker7/AML/assignment2/venv/lib/python3.8/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'NaiveBayes' already exists. Creating a new version of this model...\n",
      "2023/02/27 22:40:47 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: NaiveBayes, version 2\n",
      "Created version '2' of model 'NaiveBayes'.\n"
     ]
    }
   ],
   "source": [
    "mlflow_run(MultinomialNB, \"NaiveBayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Test accuracy: 0.9677033492822966\n",
      "Test precision:  1.0\n",
      "Test recall:  0.7631578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'LogisticRegression' already exists. Creating a new version of this model...\n",
      "2023/02/27 22:40:49 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: LogisticRegression, version 2\n",
      "Created version '2' of model 'LogisticRegression'.\n"
     ]
    }
   ],
   "source": [
    "mlflow_run(LogisticRegression, \"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "Test accuracy: 0.9629186602870813\n",
      "Test precision:  1.0\n",
      "Test recall:  0.7280701754385965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'RandomForestClassifier' already exists. Creating a new version of this model...\n",
      "2023/02/27 22:40:55 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: RandomForestClassifier, version 2\n",
      "Created version '2' of model 'RandomForestClassifier'.\n"
     ]
    }
   ],
   "source": [
    "mlflow_run(RandomForestClassifier, \"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for NaiveBayes:  0.662878787878788\n",
      "AUC for LogisticRegression:  0.7613636363636364\n",
      "AUC for RandomForestClassifier:  0.7348484848484849\n"
     ]
    }
   ],
   "source": [
    "# loading the saved models and printing AUCPR\n",
    "# the model paths were found using: mlflow ui\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "def get_auc(model):\n",
    "    test_predictions = model.predict(test_matrix)\n",
    "    precision, recall, _ = precision_recall_curve(test_labels, test_predictions)\n",
    "    return auc(precision, recall)\n",
    "\n",
    "NaiveBayes = mlflow.pyfunc.load_model(\"runs:/11341006aabf46cd94f65572712d590a/model\")\n",
    "LogisticRegression = mlflow.pyfunc.load_model(\"runs:/a211eafb22c94b63b49575f2a2f25a28/model\")\n",
    "RandomForestClassifier = mlflow.pyfunc.load_model(\"runs:/3b873f98c1594a78b4f44a06b71224f4/model\")\n",
    "\n",
    "print(\"AUC for NaiveBayes: \", get_auc(NaiveBayes))\n",
    "print(\"AUC for LogisticRegression: \", get_auc(LogisticRegression))\n",
    "print(\"AUC for RandomForestClassifier: \", get_auc(RandomForestClassifier))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d3f0ab15799972cfaad1fda049057ad9df686eaac780730f07545ace42c42a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
