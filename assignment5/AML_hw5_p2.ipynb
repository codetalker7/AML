{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AML Assignment 5: Part 2 (Sentiment Analysis)\n",
        "\n",
        "First, we download the dataset from Kaggle."
      ],
      "metadata": {
        "id": "U9OLiUJXnsrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install -q kaggle"
      ],
      "metadata": {
        "id": "QQa3uOUPH-yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "HlP5CVKNILa-",
        "outputId": "f8415de5-9e73-4b90-bc59-364f04d0edba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-34b50770-6958-4f9b-9d70-9216a905c05c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-34b50770-6958-4f9b-9d70-9216a905c05c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"codetalker7\",\"key\":\"ac82aa369636a45b525075f4b32b61ed\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle \n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ytgKaM_IMSr",
        "outputId": "5063c79e-f504-458b-98df-758971f53563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                            title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "salvatorerastelli/spotify-and-youtube                          Spotify and Youtube                                   9MB  2023-03-20 15:43:25          10798        384  1.0              \n",
            "arnabchaki/data-science-salaries-2023                          Data Science Salaries 2023  💸                        25KB  2023-04-13 09:55:16           4757        114  1.0              \n",
            "erdemtaha/cancer-data                                          Cancer Data                                          49KB  2023-03-22 07:57:00           5346        108  1.0              \n",
            "evangower/premier-league-2022-2023                             Premier League 2022-2023                              7KB  2023-04-14 19:45:22            982         34  1.0              \n",
            "lokeshparab/amazon-products-dataset                            Amazon Products Sales Dataset 2023                   80MB  2023-03-26 10:45:19           5650        121  1.0              \n",
            "iammustafatz/diabetes-prediction-dataset                       Diabetes prediction dataset                         734KB  2023-04-08 06:11:45           2446         45  1.0              \n",
            "ulrikthygepedersen/fastfood-nutrition                          Fastfood Nutrition                                   12KB  2023-03-21 10:02:41           4522         89  1.0              \n",
            "mikoajfish99/us-recession-and-financial-indicators             🏛️  Financial Indicators of US Recession 📉          989KB  2023-04-17 13:54:47            636         30  1.0              \n",
            "desalegngeb/students-exam-scores                               Students Exam Scores: Extended Dataset              695KB  2023-04-14 00:15:38           1750         42  1.0              \n",
            "rkiattisak/student-performance-in-mathematics                  Student performance prediction                        9KB  2023-03-12 04:32:56          10424        227  1.0              \n",
            "ppb00x/credit-risk-customers                                   credit_risk_customers                                18KB  2023-04-12 08:28:28           1835         47  1.0              \n",
            "ritwikb3/heart-disease-cleveland                               Heart Disease Cleveland                               3KB  2023-03-28 17:48:48            819         25  1.0              \n",
            "ppb00x/country-gdp                                             Country_GDP                                           7KB  2023-04-07 06:47:36           1640         42  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                          Melbourne Housing Snapshot                          451KB  2018-06-05 12:52:24         113826       1252  0.7058824        \n",
            "r1shabhgupta/google-stock-price-daily-weekly-and-monthly-2023  Google Stock Price: Daily, Weekly & Monthly (2023)   61KB  2023-04-15 18:23:08            856         33  1.0              \n",
            "omartorres25/honda-data                                        Honda Cars Data                                     184KB  2023-03-28 04:19:11           1879         36  1.0              \n",
            "harshghadiya/kidneystone                                       Kidney Stone Dataset                                  2KB  2023-04-12 06:09:00            990         25  0.8235294        \n",
            "ashishraut64/internet-users                                    Global Internet users                               163KB  2023-03-29 12:25:13           3003         70  1.0              \n",
            "andrezaza/clapper-massive-rotten-tomatoes-movies-and-reviews   🎬 Massive Rotten Tomatoes Movies & Reviews          152MB  2023-04-13 10:58:54            810         34  1.0              \n",
            "r1chardson/the-world-university-rankings-2011-2023             THE World University Rankings 2011-2023               1MB  2023-04-03 12:43:37           2852         62  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d abhi8923shriv/sentiment-analysis-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2cj4wiSINPk",
        "outputId": "af9899fb-b3bd-4023-e857-76fa8b985538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sentiment-analysis-dataset.zip to /content\n",
            " 92% 50.0M/54.4M [00:02<00:00, 34.5MB/s]\n",
            "100% 54.4M/54.4M [00:02<00:00, 24.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we extract our dataset."
      ],
      "metadata": {
        "id": "_3hGjEWAn3Bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip sentiment-analysis-dataset.zip -d sentiment-analysis-dataset/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNpmqzMLIOZC",
        "outputId": "39d3cd0d-9619-4106-f78e-68d778813b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sentiment-analysis-dataset.zip\n",
            "  inflating: sentiment-analysis-dataset/test.csv  \n",
            "  inflating: sentiment-analysis-dataset/testdata.manual.2009.06.14.csv  \n",
            "  inflating: sentiment-analysis-dataset/train.csv  \n",
            "  inflating: sentiment-analysis-dataset/training.1600000.processed.noemoticon.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we install the required libraries and download a few `nltk` assets."
      ],
      "metadata": {
        "id": "VolXUogZn48v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install transformers\n",
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR3iQcSwIPGg",
        "outputId": "865195a5-38ca-47e6-fd1a-69d92bb10ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we import the required modules."
      ],
      "metadata": {
        "id": "LLmwuRbyn__g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "u9_uzGwRIVZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function called `mapSentimentToInteger`, which maps `\"negative\"` to `0`, `\"neutral\"` to `1` and `\"positive\"` to `2`; this function will be used to encode the labels."
      ],
      "metadata": {
        "id": "1UOVCZqhoCf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mapSentimentToInteger(sentiment):\n",
        "    if sentiment == \"negative\":\n",
        "        return 0\n",
        "    elif sentiment == \"neutral\":\n",
        "        return 1\n",
        "    else:\n",
        "        return 2"
      ],
      "metadata": {
        "id": "Vu5rQ1fsIqxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we determine the character encoding of the dataset."
      ],
      "metadata": {
        "id": "J7VLtWAYoT1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the chardet library\n",
        "!pip install chardet\n",
        "\n",
        "# import the chardet library\n",
        "import chardet \n",
        "\n",
        "# use the detect method to find the encoding\n",
        "# 'rb' means read in the file as binary\n",
        "with open(\"sentiment-analysis-dataset/train.csv\", 'rb') as file:\n",
        "    print(chardet.detect(file.read()))\n",
        "\n",
        "with open(\"sentiment-analysis-dataset/test.csv\", 'rb') as file:\n",
        "    print(chardet.detect(file.read()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd0IfVTuItdt",
        "outputId": "39350256-57ed-419d-fe08-f0f02cc2adc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "{'encoding': 'Windows-1252', 'confidence': 0.7294331332807429, 'language': ''}\n",
            "{'encoding': 'Windows-1252', 'confidence': 0.7296655868590688, 'language': ''}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we create the training, validation and testing datasets."
      ],
      "metadata": {
        "id": "HkbWg0CvoXC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_train_val = pd.read_csv(\"sentiment-analysis-dataset/train.csv\", encoding=\"Windows-1252\", keep_default_na=False)\n",
        "sentiment_test = pd.read_csv(\"sentiment-analysis-dataset/test.csv\", encoding=\"Windows-1252\",  keep_default_na=False)\n",
        "\n",
        "sentiment_train_val_text = [sentiment_train_val[\"text\"][i] for i in range(len(sentiment_train_val))]\n",
        "sentiment_test_text = [sentiment_test[\"text\"][i] for i in range(len(sentiment_test))]\n",
        "\n",
        "sentiment_train_val_labels = [mapSentimentToInteger(sentiment_train_val[\"sentiment\"][i]) for i in range(len(sentiment_train_val))]\n",
        "sentiment_test_labels = [mapSentimentToInteger(sentiment_test[\"sentiment\"][i]) for i in range(len(sentiment_test))]\n",
        "\n",
        "sentiment_train_text, sentiment_val_text, sentiment_train_labels, sentiment_val_labels = train_test_split(sentiment_train_val_text, sentiment_train_val_labels, random_state=2018, test_size=0.3)"
      ],
      "metadata": {
        "id": "b8_7rLHNIwpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training size:\", len(sentiment_train_text))\n",
        "print(\"Validation size:\", len(sentiment_test_text))\n",
        "print(\"Testing size:\", len(sentiment_val_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSQjC6LLI53U",
        "outputId": "512919e7-7f48-4c54-a5ab-2be8d5820da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training size: 19236\n",
            "Validation size: 4815\n",
            "Testing size: 8245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now load the pretrained model and tokenizer."
      ],
      "metadata": {
        "id": "o4LC_6VxoaxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhDZZVedI9dy",
        "outputId": "c017e615-3e5b-4ebc-9805-c2148eb5b804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a sense of the possible maximum length of any sequence length in the dataset, we plot a histogram."
      ],
      "metadata": {
        "id": "76TRtBUQofXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(text.split()) for text in sentiment_train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "InkVeI9aIjrc",
        "outputId": "c69ef81f-eb66-4064-88c4-94b20e1ed8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_len = 25"
      ],
      "metadata": {
        "id": "h-WQK0D6IxcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a max length of 25, we tokenize the training, validation and testing data."
      ],
      "metadata": {
        "id": "4xb7aCd4opCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    sentiment_train_text,\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    sentiment_val_text,\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    sentiment_test_text,\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSvYs3yXI1RL",
        "outputId": "83b864d7-4b87-4661-de44-d697642e9a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we convert the different components of the datasets to tensors."
      ],
      "metadata": {
        "id": "k3rJ4iO5ot51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(sentiment_train_labels)\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(sentiment_val_labels)\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(sentiment_test_labels)"
      ],
      "metadata": {
        "id": "m11bpbStOjEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now initialize `DataLoader` objects, and also initialize the batch size."
      ],
      "metadata": {
        "id": "i1OFWqjDo1Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "TUIEkG3YO6FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, we will freeze all the parameters of the model."
      ],
      "metadata": {
        "id": "zSfrljDwo7pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "9Y9cIWEsO_G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now define a simple architecture for our model. In this architecture, we will use the preloaded `bert` model."
      ],
      "metadata": {
        "id": "o2VFRsSBo-c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert):\n",
        "      super(BERT_Arch, self).__init__()\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,3)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "      #pass the inputs to the model  \n",
        "      outputs = self.bert(sent_id, attention_mask=mask).pooler_output\n",
        "      x = self.fc1(outputs)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "95Lj3upHPK8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we initialize our model, and define the loss function and the optimizer."
      ],
      "metadata": {
        "id": "gCEBE444pGjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "IL8xLlYrP1Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtQB8VzGP6O7",
        "outputId": "77d8f793-5c08-45ea-832b-464190882779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(class_weight='balanced', classes=np.unique(sentiment_train_labels), y=sentiment_train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTQbkw3uQo8b",
        "outputId": "12703994-0950-44e7-8257-dc226a606efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.17737789 0.82247306 1.0697364 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "2DNszoP2RBw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we define a function which represents one step of training."
      ],
      "metadata": {
        "id": "f6ys1d-BpPp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "    \n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "    \n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "    \n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # clear previously calculated gradients \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "\n",
        "        # append the model predictions\n",
        "        total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    \n",
        "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "Wrqjl-RiREuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also define a function to evaluate the model on the validation dataset."
      ],
      "metadata": {
        "id": "SFHr0vz2pTKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds\n",
        "     "
      ],
      "metadata": {
        "id": "KsGpE1CeS6nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we train the model."
      ],
      "metadata": {
        "id": "pGy66O5upVsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyQp8xM3RZYC",
        "outputId": "2fd970e7-cbae-4b41-d479-2f548fcae17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.121\n",
            "Validation Loss: 1.099\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.099\n",
            "Validation Loss: 1.099\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.099\n",
            "Validation Loss: 1.099\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.099\n",
            "Validation Loss: 1.099\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.099\n",
            "Validation Loss: 1.099\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.101\n",
            "Validation Loss: 1.099\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.099\n",
            "Validation Loss: 1.099\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.099\n",
            "Validation Loss: 1.099\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.099\n",
            "Validation Loss: 1.099\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of    602.\n",
            "  Batch   100  of    602.\n",
            "  Batch   150  of    602.\n",
            "  Batch   200  of    602.\n",
            "  Batch   250  of    602.\n",
            "  Batch   300  of    602.\n",
            "  Batch   350  of    602.\n",
            "  Batch   400  of    602.\n",
            "  Batch   450  of    602.\n",
            "  Batch   500  of    602.\n",
            "  Batch   550  of    602.\n",
            "  Batch   600  of    602.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    258.\n",
            "  Batch   100  of    258.\n",
            "  Batch   150  of    258.\n",
            "  Batch   200  of    258.\n",
            "  Batch   250  of    258.\n",
            "\n",
            "Training Loss: 1.099\n",
            "Validation Loss: 1.099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After this, we print the classification report on the test dataset."
      ],
      "metadata": {
        "id": "1txkv40lpXcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "c930MXDDbGkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjkuKTuEbTU2",
        "outputId": "b8efc2a0-0a16-4476-f1d9-63b0d9c097ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1001\n",
            "           1       0.30      1.00      0.46      1430\n",
            "           2       0.00      0.00      0.00      2384\n",
            "\n",
            "    accuracy                           0.30      4815\n",
            "   macro avg       0.10      0.33      0.15      4815\n",
            "weighted avg       0.09      0.30      0.14      4815\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}